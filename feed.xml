<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://zinuoli.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://zinuoli.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-12-11T10:29:31+00:00</updated><id>https://zinuoli.github.io/feed.xml</id><title type="html">blank</title><subtitle>PhD student at University of Western Australia, focusing on Video Understanding, Multimodal Large Language Models, and Visual Reasoning. </subtitle><entry><title type="html">My Journey into Multimodal Large Language Models</title><link href="https://zinuoli.github.io/blog/2024/multimodal-llm-journey/" rel="alternate" type="text/html" title="My Journey into Multimodal Large Language Models"/><published>2024-12-01T10:00:00+00:00</published><updated>2024-12-01T10:00:00+00:00</updated><id>https://zinuoli.github.io/blog/2024/multimodal-llm-journey</id><content type="html" xml:base="https://zinuoli.github.io/blog/2024/multimodal-llm-journey/"><![CDATA[<p>As a PhD student working on multimodal large language models (MLLMs), I’ve been fascinated by the rapid progress in this field. The ability to understand and reason across different modalities - vision, audio, and text - opens up incredible possibilities for AI applications.</p> <h2 id="the-challenge-of-multimodal-understanding">The Challenge of Multimodal Understanding</h2> <p>One of the most exciting challenges in AI today is teaching machines to understand the world the way humans do - through multiple senses simultaneously. When we watch a video, we don’t just see the visual content; we hear the audio, understand the speech, and integrate all these signals to form a comprehensive understanding.</p> <h2 id="our-approach-trisense">Our Approach: TriSense</h2> <p>In our recent work “TriSense,” we tackled the problem of understanding audio-visual-speech moments in videos. The key insight was that these three modalities are not independent - they work together to create meaning. A person’s facial expressions, their tone of voice, and the words they speak all contribute to the overall message.</p> <h2 id="looking-forward">Looking Forward</h2> <p>The field of multimodal AI is evolving rapidly, and I’m excited to be part of this journey. As we continue to push the boundaries of what’s possible, I believe we’ll see increasingly sophisticated AI systems that can understand and interact with the world in more human-like ways.</p> <p>Stay tuned for more updates on my research journey!</p>]]></content><author><name></name></author><category term="research"/><category term="multimodal-ai"/><category term="video-understanding"/><category term="research"/><summary type="html"><![CDATA[Exploring the fascinating world of multimodal AI and its applications in video understanding]]></summary></entry><entry><title type="html">Tackling Document Shadow Removal with Deep Learning</title><link href="https://zinuoli.github.io/blog/2024/document-shadow-removal/" rel="alternate" type="text/html" title="Tackling Document Shadow Removal with Deep Learning"/><published>2024-06-15T14:30:00+00:00</published><updated>2024-06-15T14:30:00+00:00</updated><id>https://zinuoli.github.io/blog/2024/document-shadow-removal</id><content type="html" xml:base="https://zinuoli.github.io/blog/2024/document-shadow-removal/"><![CDATA[<p>Document digitization is everywhere in our modern world, but shadows cast on documents during scanning or photography can significantly degrade the quality and readability of the digitized content. This seemingly simple problem turned out to be quite challenging to solve effectively.</p> <h2 id="the-problem-with-existing-approaches">The Problem with Existing Approaches</h2> <p>Most existing methods for shadow removal were designed for natural images, not documents. Documents have unique characteristics:</p> <ul> <li>High contrast between text and background</li> <li>Geometric structures and layouts</li> <li>Sensitivity to artifacts that might not matter in natural images</li> </ul> <h2 id="our-solution-sd7k-dataset-and-frequency-aware-network">Our Solution: SD7K Dataset and Frequency-Aware Network</h2> <p>We created SD7K, a large-scale real-world dataset specifically for document shadow removal. What makes this dataset special:</p> <ol> <li><strong>Real-world diversity</strong>: Captured under various lighting conditions and document types</li> <li><strong>High resolution</strong>: Maintaining the quality needed for practical applications</li> <li><strong>Comprehensive annotations</strong>: Carefully labeled shadow regions and clean references</li> </ol> <p>Along with the dataset, we developed a frequency-aware shadow erasing network that:</p> <ul> <li>Analyzes shadows in the frequency domain</li> <li>Preserves document structure while removing shadows</li> <li>Achieves state-of-the-art performance on benchmark datasets</li> </ul> <h2 id="impact-and-applications">Impact and Applications</h2> <p>This work has practical implications for:</p> <ul> <li>Document digitization workflows</li> <li>Optical Character Recognition (OCR) systems</li> <li>Archive preservation projects</li> <li>Mobile document scanning applications</li> </ul> <p>The combination of a high-quality dataset and an effective algorithm opens up new possibilities for automated document processing pipelines.</p>]]></content><author><name></name></author><category term="research"/><category term="computer-vision"/><category term="document-analysis"/><category term="deep-learning"/><summary type="html"><![CDATA[How we built SD7K, a large-scale dataset for document shadow removal]]></summary></entry><entry><title type="html">Reflections on PhD Life and Research</title><link href="https://zinuoli.github.io/blog/2024/phd-life-reflections/" rel="alternate" type="text/html" title="Reflections on PhD Life and Research"/><published>2024-03-20T16:00:00+00:00</published><updated>2024-03-20T16:00:00+00:00</updated><id>https://zinuoli.github.io/blog/2024/phd-life-reflections</id><content type="html" xml:base="https://zinuoli.github.io/blog/2024/phd-life-reflections/"><![CDATA[<p>Starting a PhD is both exciting and daunting. As I reflect on my first few months at the University of Western Australia, I wanted to share some thoughts on this journey.</p> <h2 id="the-transition">The Transition</h2> <p>Moving from being a research assistant to a PhD student involves a significant shift in mindset. You’re no longer just executing research tasks - you’re expected to identify problems, propose solutions, and drive your own research agenda.</p> <h2 id="working-with-multiple-supervisors">Working with Multiple Supervisors</h2> <p>I’m fortunate to work with an amazing team of supervisors:</p> <ul> <li><strong>Prof. Mohammed Bennamoun</strong> and <strong>Prof. Farid Boussaid</strong> at UWA provide the local support and institutional framework</li> <li><strong>Dr. Qiuhong Ke</strong> at Monash University brings expertise in video understanding and multimodal learning</li> </ul> <p>This collaborative arrangement has been incredibly valuable, offering diverse perspectives and expertise.</p> <h2 id="research-focus-evolution">Research Focus Evolution</h2> <p>My research interests have evolved from traditional computer vision problems (like document analysis and image enhancement) toward more complex multimodal understanding tasks. This evolution reflects both personal interests and the rapidly changing landscape of AI research.</p> <h2 id="challenges-and-growth">Challenges and Growth</h2> <p>Some key challenges I’ve encountered:</p> <ul> <li><strong>Scope management</strong>: Learning to focus on specific, well-defined problems</li> <li><strong>Literature review</strong>: Staying current with the rapidly evolving field</li> <li><strong>Technical depth</strong>: Balancing breadth of knowledge with deep expertise</li> <li><strong>Time management</strong>: Juggling research, coursework, and other responsibilities</li> </ul> <h2 id="looking-ahead">Looking Ahead</h2> <p>I’m excited about the opportunities ahead, particularly in multimodal AI and video understanding. The field is moving so quickly that there are always new problems to solve and new techniques to explore.</p> <p>For anyone considering a PhD journey, my advice would be: embrace the uncertainty, stay curious, and don’t be afraid to ask questions. The research community is generally very supportive and collaborative.</p>]]></content><author><name></name></author><category term="personal"/><category term="phd-life"/><category term="research"/><category term="academia"/><summary type="html"><![CDATA[Thoughts on starting my PhD journey at UWA and the challenges of research]]></summary></entry></feed>