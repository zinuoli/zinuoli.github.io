---
---

@article{li2025trisense,
  title={Watch and Listen: Understanding Audio-Visual-Speech Moments with Multimodal LLM},
  author={Li, Zinuo and Zhang, Xian and Guo, Yongxin and Bennamoun, Mohammed and Boussaid, Farid and Dwivedi, Girish and Gong, Luqi and Ke, Qiuhong},
  journal={Advances in Neural Information Processing Systems},
  abbr={NeurIPS},
  ccf={CCF-A},
  core={CORE-A*},
  selected={true},
  keywords={Multimodal Learning, Video Understanding},
  preview={trisense.png},
  pdf={https://arxiv.org/pdf/2505.18110},
  code={https://github.com/zinuoli/TriSense},
  abstract={We present TriSense, a novel multimodal large language model that can understand audio-visual-speech moments in videos. Our approach combines visual, audio, and speech modalities to provide comprehensive video understanding capabilities.},
  year={2025}
}

@article{li2023sd7k,
  title={High-resolution Document Shadow Removal via A Large-scale Real-world Dataset and A Frequency-aware Shadow Erasing Net},
  author={Li, Zinuo and Chen, Xuhang and Pun, Chi-Man and Cun, Xiaodong},
  journal={IEEE/CVF International Conference on Computer Vision},
  abbr={ICCV},
  ccf={CCF-A},
  core={CORE-A*},
  selected={true},
  keywords={Document Analysis, Shadow Removal},
  preview={sd7k.jpg},
  pdf={https://arxiv.org/abs/2308.14221},
  code={https://github.com/CXH-Research/DocShadow-SD7K},
  abstract={We introduce SD7K, a large-scale real-world dataset for document shadow removal, along with a frequency-aware shadow erasing network. Our approach achieves state-of-the-art performance on document shadow removal tasks.},
  year={2023}
}

@article{li2023filmnet,
  title={A Large-scale Film Style Dataset for Learning Multi-frequency Driven Film Enhancement},
  author={Li, Zinuo and Chen, Xuhang and Pun, Chi-Man and Wang, Shuqiang},
  journal={International Joint Conference on Artificial Intelligence},
  abbr={IJCAI},
  ccf={CCF-A},
  core={CORE-A*},
  selected={true},
  keywords={Film Enhancement, Style Transfer},
  preview={filmset.png},
  pdf={https://arxiv.org/abs/2301.08880},
  code={https://github.com/CXH-Research/FilmNet},
  abstract={We present FilmNet, a comprehensive framework for film enhancement using a large-scale film style dataset. Our multi-frequency driven approach enables high-quality film style transfer and enhancement.},
  year={2023}
}

@article{luo2024devignet,
  title={Devignet: High-Resolution Vignetting Removal via a Dual Aggregated Fusion Transformer With Adaptive Channel Expansion},
  author={Luo, Shenghong and Chen, Xuhang and Chen, Weiwen and Li, Zinuo and Wang, Shuqiang and Pun, Chi-Man},
  journal={AAAI Conference on Artificial Intelligence},
  abbr={AAAI},
  ccf={CCF-A},
  core={CORE-A*},
  selected={true},
  keywords={Image Enhancement, Vignetting Removal},
  preview={devignet.jpg},
  pdf={https://arxiv.org/abs/2308.13739},
  code={https://github.com/CXH-Research/DeVigNet},
  abstract={We propose DeVigNet, a novel dual aggregated fusion transformer for high-resolution vignetting removal. Our approach uses adaptive channel expansion to effectively remove vignetting effects while preserving image details.},
  year={2024}
}